{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ccbaead88c86434e8f04af57c00cd74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_714e74791f7842eead6aacd585da81a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_166a89e0cfe4401f9ea828b85caa84af",
              "IPY_MODEL_f749f62667db453bb971ad4f0e58cedf"
            ]
          }
        },
        "714e74791f7842eead6aacd585da81a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "166a89e0cfe4401f9ea828b85caa84af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_192f6bac830c45b0847677da00065515",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90898fe5569147388df2d37a8a6724a8"
          }
        },
        "f749f62667db453bb971ad4f0e58cedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b2b42b7ba124914ac429e03efe2569b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 238kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f130545b9f5040f3bf9c889fd32e7a81"
          }
        },
        "192f6bac830c45b0847677da00065515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90898fe5569147388df2d37a8a6724a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b2b42b7ba124914ac429e03efe2569b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f130545b9f5040f3bf9c889fd32e7a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "994899e34a284b90950fc0ee573d6c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce49e85216d948eaa873117fc7caf56b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69b8733997524bdd8e2189b225a37141",
              "IPY_MODEL_85cf2d8a91ad42758a1bae2ff2436ed4"
            ]
          }
        },
        "ce49e85216d948eaa873117fc7caf56b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69b8733997524bdd8e2189b225a37141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25d6cc9a1cab4f729e6354fe8bdf5c2d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34c9534aa56f4458bf83f67f04132edc"
          }
        },
        "85cf2d8a91ad42758a1bae2ff2436ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3eed88ae70194b13bbc5ac89959c6c15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.07kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac351c43bb124e45b0ab5c1c0b1599db"
          }
        },
        "25d6cc9a1cab4f729e6354fe8bdf5c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34c9534aa56f4458bf83f67f04132edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3eed88ae70194b13bbc5ac89959c6c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac351c43bb124e45b0ab5c1c0b1599db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69684d89aa9e4078a7a23679eab286be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ff69e855d9a4da8b644d224c3e3d126",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_14f3d960c13648098df214812183cc4a",
              "IPY_MODEL_e0e2112d3cc34f9f9fb243a8420e2b2e"
            ]
          }
        },
        "9ff69e855d9a4da8b644d224c3e3d126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14f3d960c13648098df214812183cc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ffd77921d6204e8da55596fe1e46bb10",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 526681800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 526681800,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da9e0287fe034710814ff6d4d932bc18"
          }
        },
        "e0e2112d3cc34f9f9fb243a8420e2b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_017c26b3c550492f8e4d6a7e75eb1203",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 527M/527M [00:07&lt;00:00, 71.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76005f53a27e4122b1a1bcaf361b6298"
          }
        },
        "ffd77921d6204e8da55596fe1e46bb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da9e0287fe034710814ff6d4d932bc18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "017c26b3c550492f8e4d6a7e75eb1203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76005f53a27e4122b1a1bcaf361b6298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR8QBiJErfGb",
        "colab_type": "text"
      },
      "source": [
        "# Classifying Voice Commands\n",
        "\n",
        "For voice commands, Siri needs to be able to figure out *what* the speaker wants, and then *how* to accomplish that request. \n",
        "\n",
        "<img src=\"https://www.cheatsheet.com/wp-content/uploads/2016/01/Siri-in-iOS-9-640x305.png\" width=400>\n",
        "\n",
        "Recall that we had a two-part goal:\n",
        "\n",
        "a) predict the intent of the speaker of a voice command \n",
        "\n",
        "and \n",
        "\n",
        "b) extract the interesting named entities within the command.\n",
        "\n",
        "It's now time to focus on part (b), also known as **NER**, which will help our sentence-level classification system we started in the 2nd notebook!\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/2594/1*rq7FCkcq4sqUY9IgfsPEOg.png\" width=\"500\">\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGJ7aarj5B3S",
        "colab_type": "text"
      },
      "source": [
        "**IMPORTANT**: Since the BERT model we will be using in this notebook is so large, we need to do one step before continuing. Please go to the 'Runtime' tab, and click on 'Change Runtime Type'; then select **GPU** under the dropdown for Hardware accelerator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGoMnG4dsXXi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439,
          "referenced_widgets": [
            "ccbaead88c86434e8f04af57c00cd74e",
            "714e74791f7842eead6aacd585da81a9",
            "166a89e0cfe4401f9ea828b85caa84af",
            "f749f62667db453bb971ad4f0e58cedf",
            "192f6bac830c45b0847677da00065515",
            "90898fe5569147388df2d37a8a6724a8",
            "8b2b42b7ba124914ac429e03efe2569b",
            "f130545b9f5040f3bf9c889fd32e7a81",
            "994899e34a284b90950fc0ee573d6c38",
            "ce49e85216d948eaa873117fc7caf56b",
            "69b8733997524bdd8e2189b225a37141",
            "85cf2d8a91ad42758a1bae2ff2436ed4",
            "25d6cc9a1cab4f729e6354fe8bdf5c2d",
            "34c9534aa56f4458bf83f67f04132edc",
            "3eed88ae70194b13bbc5ac89959c6c15",
            "ac351c43bb124e45b0ab5c1c0b1599db",
            "69684d89aa9e4078a7a23679eab286be",
            "9ff69e855d9a4da8b644d224c3e3d126",
            "14f3d960c13648098df214812183cc4a",
            "e0e2112d3cc34f9f9fb243a8420e2b2e",
            "ffd77921d6204e8da55596fe1e46bb10",
            "da9e0287fe034710814ff6d4d932bc18",
            "017c26b3c550492f8e4d6a7e75eb1203",
            "76005f53a27e4122b1a1bcaf361b6298"
          ]
        },
        "outputId": "e9c479d6-7f5a-40d2-f1d9-8659a3def28c"
      },
      "source": [
        "#@title Run this code to get started\n",
        "%tensorflow_version 2.x\n",
        "%pip install -q transformers\n",
        "\n",
        "import tensorflow as tf\n",
        "from urllib.request import urlretrieve\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from transformers import TFBertModel\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "SNIPS_DATA_BASE_URL = (\n",
        "    \"https://github.com/ogrisel/slot_filling_and_intent_detection_of_SLU/blob/\"\n",
        "    \"master/data/snips/\"\n",
        ")\n",
        "for filename in [\"train\", \"valid\", \"test\", \"vocab.intent\", \"vocab.slot\"]:\n",
        "    path = Path(filename)\n",
        "    if not path.exists():\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        urlretrieve(SNIPS_DATA_BASE_URL + filename + \"?raw=true\", path)\n",
        "\n",
        "\n",
        "def parse_line(line):\n",
        "    data, intent_label = line.split(\" <=> \")\n",
        "    items = data.split()\n",
        "    words = [item.rsplit(\":\", 1)[0]for item in items]\n",
        "    word_labels = [item.rsplit(\":\", 1)[1]for item in items]\n",
        "    return {\n",
        "        \"intent_label\": intent_label, \n",
        "        \"words\": \" \".join(words),\n",
        "        \"word_labels\": \" \".join(word_labels),\n",
        "        \"length\": len(words),\n",
        "    }\n",
        "\n",
        "def encode_dataset(text_sequences):\n",
        "    # Create token_ids array (initialized to all zeros), where \n",
        "    # rows are a sequence and columns are encoding ids\n",
        "    # of each token in given sequence.\n",
        "    token_ids = np.zeros(shape=(len(text_sequences), max_token_len),\n",
        "                         dtype=np.int32)\n",
        "    \n",
        "    for i, text_sequence in enumerate(text_sequences):\n",
        "        encoded = tokenizer.encode(text_sequence)\n",
        "        token_ids[i, 0:len(encoded)] = encoded\n",
        "\n",
        "    attention_masks = (token_ids != 0).astype(np.int32)\n",
        "    return {\"input_ids\": token_ids, \"attention_masks\": attention_masks}\n",
        "\n",
        "\n",
        "train_lines = Path(\"train\").read_text().strip().splitlines()\n",
        "valid_lines = Path(\"valid\").read_text().strip().splitlines()\n",
        "test_lines = Path(\"test\").read_text().strip().splitlines()\n",
        "\n",
        "df_train = pd.DataFrame([parse_line(line) for line in train_lines])\n",
        "df_valid = pd.DataFrame([parse_line(line) for line in valid_lines])\n",
        "df_test = pd.DataFrame([parse_line(line) for line in test_lines])\n",
        "\n",
        "max_token_len = 43\n",
        "\n",
        "encoded_train = encode_dataset(df_train[\"words\"])\n",
        "encoded_valid = encode_dataset(df_valid[\"words\"])\n",
        "encoded_test = encode_dataset(df_test[\"words\"])\n",
        "\n",
        "intent_names = Path(\"vocab.intent\").read_text().split()\n",
        "intent_map = dict((label, idx) for idx, label in enumerate(intent_names))\n",
        "intent_train = df_train[\"intent_label\"].map(intent_map).values\n",
        "intent_valid = df_valid[\"intent_label\"].map(intent_map).values\n",
        "intent_test = df_test[\"intent_label\"].map(intent_map).values\n",
        "\n",
        "base_bert_model = TFBertModel.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 757kB 12.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 53.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 47.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccbaead88c86434e8f04af57c00cd74e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading train...\n",
            "Downloading valid...\n",
            "Downloading test...\n",
            "Downloading vocab.intent...\n",
            "Downloading vocab.slot...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "994899e34a284b90950fc0ee573d6c38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69684d89aa9e4078a7a23679eab286be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=526681800.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg6IkYg-sXBM",
        "colab_type": "text"
      },
      "source": [
        "## Intent Classification + NER\n",
        "\n",
        "Let's now refine our Natural Language Understanding system by capturing the important named elements within each voice command.\n",
        "\n",
        "To do this, we will do word (actually *token*) level classification of the BIO labels.\n",
        "\n",
        "```\n",
        "      Book : O\n",
        "         a : O\n",
        "     table : O\n",
        "       for : O\n",
        "       two : B-party_size_number\n",
        "        at : O\n",
        "        Le : B-restaurant_name\n",
        "         R : I-restaurant_name\n",
        "     ##itz : I-restaurant_name\n",
        "       for : O\n",
        "    Friday : B-timeRange\n",
        "     night : I-timeRange\n",
        "         ! : O\n",
        "```\n",
        "\n",
        "Note: Since we have *word* level tags but BERT uses a tokenizer, we need to align the BIO labels with the BERT *tokens*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bv9qrtdsogG",
        "colab_type": "text"
      },
      "source": [
        "First, let's load the list of possible word token labels and augment it with an additional padding label so we can ignore special tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HtO77h2snDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59e822ae-60fe-4410-d23e-2944d25f5acc"
      },
      "source": [
        "# Build a map from slot name to a unique id.\n",
        "slot_names = [\"[PAD]\"] + Path(\"vocab.slot\").read_text().strip().splitlines()\n",
        "slot_map = {}\n",
        "for label in slot_names:\n",
        "    slot_map[label] = len(slot_map)\n",
        "slot_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-album': 1,\n",
              " 'B-artist': 2,\n",
              " 'B-best_rating': 3,\n",
              " 'B-city': 4,\n",
              " 'B-condition_description': 5,\n",
              " 'B-condition_temperature': 6,\n",
              " 'B-country': 7,\n",
              " 'B-cuisine': 8,\n",
              " 'B-current_location': 9,\n",
              " 'B-entity_name': 10,\n",
              " 'B-facility': 11,\n",
              " 'B-genre': 12,\n",
              " 'B-geographic_poi': 13,\n",
              " 'B-location_name': 14,\n",
              " 'B-movie_name': 15,\n",
              " 'B-movie_type': 16,\n",
              " 'B-music_item': 17,\n",
              " 'B-object_location_type': 18,\n",
              " 'B-object_name': 19,\n",
              " 'B-object_part_of_series_type': 20,\n",
              " 'B-object_select': 21,\n",
              " 'B-object_type': 22,\n",
              " 'B-party_size_description': 23,\n",
              " 'B-party_size_number': 24,\n",
              " 'B-playlist': 25,\n",
              " 'B-playlist_owner': 26,\n",
              " 'B-poi': 27,\n",
              " 'B-rating_unit': 28,\n",
              " 'B-rating_value': 29,\n",
              " 'B-restaurant_name': 30,\n",
              " 'B-restaurant_type': 31,\n",
              " 'B-served_dish': 32,\n",
              " 'B-service': 33,\n",
              " 'B-sort': 34,\n",
              " 'B-spatial_relation': 35,\n",
              " 'B-state': 36,\n",
              " 'B-timeRange': 37,\n",
              " 'B-track': 38,\n",
              " 'B-year': 39,\n",
              " 'I-album': 40,\n",
              " 'I-artist': 41,\n",
              " 'I-city': 42,\n",
              " 'I-country': 43,\n",
              " 'I-cuisine': 44,\n",
              " 'I-current_location': 45,\n",
              " 'I-entity_name': 46,\n",
              " 'I-facility': 47,\n",
              " 'I-genre': 48,\n",
              " 'I-geographic_poi': 49,\n",
              " 'I-location_name': 50,\n",
              " 'I-movie_name': 51,\n",
              " 'I-movie_type': 52,\n",
              " 'I-music_item': 53,\n",
              " 'I-object_location_type': 54,\n",
              " 'I-object_name': 55,\n",
              " 'I-object_part_of_series_type': 56,\n",
              " 'I-object_select': 57,\n",
              " 'I-object_type': 58,\n",
              " 'I-party_size_description': 59,\n",
              " 'I-playlist': 60,\n",
              " 'I-playlist_owner': 61,\n",
              " 'I-poi': 62,\n",
              " 'I-restaurant_name': 63,\n",
              " 'I-restaurant_type': 64,\n",
              " 'I-served_dish': 65,\n",
              " 'I-service': 66,\n",
              " 'I-sort': 67,\n",
              " 'I-spatial_relation': 68,\n",
              " 'I-state': 69,\n",
              " 'I-timeRange': 70,\n",
              " 'I-track': 71,\n",
              " 'O': 72,\n",
              " '[PAD]': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH8T5IuKsw5-",
        "colab_type": "text"
      },
      "source": [
        "#### Word to Token Encodings\n",
        "\n",
        "The following function generates *token-aligned* integer ids from the BIO *word-level* annotations. <img src=\"https://www.emoji.co.uk/files/twitter-emojis/symbols-twitter/11214-anticlockwise-downwards-and-upwards-open-circle-arrows.png\" width=20>\n",
        "\n",
        "If a certain word is broken down into multiple tokens by BERT, the word-level label is replicated for all of the word's tokens. The \"B-\" prefix is only used for the 1st of the tokens, while the rest of the tokens have the same label but with the \"I-\" prefix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeChi7UlsxWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uses the slot_map of slot name to unique id, defined above, as well\n",
        "# as the BERT tokenizer to create a np array with each row corresponding\n",
        "# to a given sequence, and the columns as the id of the given token slot labels.\n",
        "def encode_token_labels(text_sequences, true_word_labels):\n",
        "    encoded = np.zeros(shape=(len(text_sequences), max_token_len), dtype=np.int32)\n",
        "    for i, (text_sequence, word_labels) in enumerate( \\\n",
        "            zip(text_sequences, true_word_labels)):\n",
        "        encoded_labels = []\n",
        "        for word, word_label in zip(text_sequence.split(), word_labels.split()):\n",
        "            tokens = tokenizer.tokenize(word)\n",
        "            encoded_labels.append(slot_map[word_label])\n",
        "            expand_label = word_label.replace(\"B-\", \"I-\")\n",
        "            if not expand_label in slot_map:\n",
        "                expand_label = word_label\n",
        "            encoded_labels.extend([slot_map[expand_label]] * (len(tokens) - 1))\n",
        "        encoded[i, 1:len(encoded_labels) + 1] = encoded_labels\n",
        "    return encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gWgEv025AUM",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 1\n",
        "\n",
        "Let's encode the token labels for train, validation, & test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_E2mYLys06d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the token labels and store in variables slot_train, slot_valid, slot_test.\n",
        "### YOUR CODE HERE ###\n",
        "slot_train = encode_token_labels(df_train[\"words\"], df_train[\"word_labels\"])\n",
        "slot_valid = encode_token_labels(df_valid[\"words\"], df_valid[\"word_labels\"])\n",
        "slot_test = encode_token_labels(df_test[\"words\"], df_test[\"word_labels\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZG9hgDUtYYZ",
        "colab_type": "text"
      },
      "source": [
        "Let's look at what the encoded token labels for the 1st training sequence are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXc6Tzlks3Tn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6fb2c032-72ce-41b0-97f0-7aeed6d2f708"
      },
      "source": [
        "slot_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 72, 72, 10, 46, 46, 46, 72, 26, 25, 60, 60, 60, 60, 60, 60, 72,\n",
              "       72,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb-CwwQntcHG",
        "colab_type": "text"
      },
      "source": [
        "Remember that special tokens such as `[PAD]` and `[SEP]` as well as all padded positions have a 0 label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f4ZxkdoteCD",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 2\n",
        "\n",
        "Let's finish filling out the code below to build our **joint sequence and token classification model** which will be trained on our encoded dataset with the NER labels <img src=\"https://www.dictionary.com/e/wp-content/uploads/2018/08/victory-hand.png\" width=20>:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn5MWCeOtefa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the class for the model that will create predictions\n",
        "# for the overall intent of a sequence, as well as the NER token labels.\n",
        "class JointIntentAndSlotFillingModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n",
        "                dropout_prob=0.1):\n",
        "        super().__init__(name=\"joint_intent_slot\")\n",
        "\n",
        "        self.bert = base_bert_model\n",
        "        \n",
        "# TODO: define the dropout, intent & slot classifier layers\n",
        "        ### YOUR CODE HERE ###\n",
        "        self.dropout = Dropout(dropout_prob)\n",
        "        self.intent_classifier = Dense(intent_num_labels,\n",
        "                                       name=\"intent_classifier\")\n",
        "        self.slot_classifier = Dense(slot_num_labels,\n",
        "                                     name=\"slot_classifier\")\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # Extract features from the inputs using pre-trained BERT.\n",
        "        # TODO: what does the bert model return?\n",
        "        tokens_output, tokens_output = self.bert(inputs, **kwargs)\n",
        "\n",
        "        # TODO: use the new layers to predict slot class (logits) for each\n",
        "        # token position in input sequence (size: (batch_size, seq_len, slot_num_labels)).\n",
        "        # (Hint: create sequence_output to get the slot_logits).\n",
        "        ### YOUR CODE HERE ###\n",
        "        # Solution:\n",
        "        tokens_output = self.dropout(sequence_output,\n",
        "                                       training=kwargs.get(\"training\", False))\n",
        "        slot_logits = self.slot_classifier(sequence_output) \n",
        "\n",
        "        # TODO: define a second classification head for the sequence-wise\n",
        "        # predictions (size: (batch_size, intent_num_labels)).\n",
        "        # (Hint: create pooled_output to get the intent_logits).\n",
        "        # Remember that the 2nd output of the main BERT layer is size \n",
        "        # (batch_size, output_dim) & gives a \"pooled\" representation for \n",
        "        # full sequence from hidden state corresponding to [CLS]).\n",
        "        ### YOUR CODE HERE ###\n",
        "        # Solution:\n",
        "        pooled_output = self.dropout(pooled_output,\n",
        "                                     training=kwargs.get(\"training\", False))\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return slot_logits, intent_logits\n",
        "\n",
        "# TODO: create an instantiation of this model\n",
        "joint_model = JointIntentAndSlotFillingModel( \\\n",
        "    intent_num_labels=len(intent_map), slot_num_labels=len(slot_map))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t7cP_dWuChJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define one classification loss for each output (intent & NER):\n",
        "losses = [SparseCategoricalCrossentropy(from_logits=True),\n",
        "          SparseCategoricalCrossentropy(from_logits=True)]\n",
        "          \n",
        "joint_model.compile(optimizer=Adam(learning_rate=3e-5, epsilon=1e-08),\n",
        "                    loss=losses,\n",
        "                    metrics=[SparseCategoricalAccuracy('accuracy')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWhvmB8puECV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "41891d87-e04f-4146-f895-66524e7b34aa"
      },
      "source": [
        "# Train the model.\n",
        "history = joint_model.fit(encoded_train, (slot_train, intent_train), \\\n",
        "    validation_data=(encoded_valid, (slot_valid, intent_valid)), \\\n",
        "    epochs=1, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "409/409 [==============================] - 129s 316ms/step - loss: 0.5702 - output_1_loss: 0.3089 - output_2_loss: 0.2613 - output_1_accuracy: 0.9305 - output_2_accuracy: 0.9169 - val_loss: 0.0956 - val_output_1_loss: 0.0512 - val_output_2_loss: 0.0444 - val_output_1_accuracy: 0.9851 - val_output_2_accuracy: 0.9914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfiWEKr3uF6g",
        "colab_type": "text"
      },
      "source": [
        "We should be able to achieve 99% validation accuracy for both tasks (sequence & token predictions) after only training for one epoch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FnovtrRuIVl",
        "colab_type": "text"
      },
      "source": [
        "#### Classification\n",
        "\n",
        "<img src=\"https://orbitcarrot.com/wp-content/uploads/2014/12/predict.png\" width=100>\n",
        "\n",
        "Whew! All that's left to make predictions is the following function which uses our trained model to make a prediction on a single text sequence, & display both the sequence-wise and the token-wise class labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfjmGfi8Ks2",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 3\n",
        "\n",
        "Let's finish the following function to make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq9qh16auKqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the model we trained to get the intent & slot logits\n",
        "# and print the actual string of the class corresponding to\n",
        "# highest logit score for each token, and the sentence overall.\n",
        "def show_predictions(text, intent_names, slot_names):\n",
        "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n",
        "    outputs = joint_model(inputs)\n",
        "    slot_logits, intent_logits = outputs\n",
        "    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n",
        "    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
        "    print(\"## Intent:\", intent_names[intent_id])\n",
        "    print(\"## Slots:\")\n",
        "    for token, slot_id in zip(tokenizer.tokenize(text), slot_ids):\n",
        "        print(f\"{token:>10} : {slot_names[slot_id]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvwcHegauMLn",
        "colab_type": "text"
      },
      "source": [
        "Let's see how our classification function works on some examples!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYp8Z4-AuOGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a9af78b5-b6a4-45aa-e7c2-a6849c18305a"
      },
      "source": [
        "show_predictions(\"Book a table for two at Le Ritz for Friday night!\", intent_names, slot_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Intent: BookRestaurant\n",
            "## Slots:\n",
            "      Book : O\n",
            "         a : O\n",
            "     table : O\n",
            "       for : O\n",
            "       two : B-party_size_number\n",
            "        at : O\n",
            "        Le : I-restaurant_name\n",
            "         R : I-restaurant_name\n",
            "     ##itz : I-restaurant_name\n",
            "       for : O\n",
            "    Friday : B-timeRange\n",
            "     night : I-timeRange\n",
            "         ! : O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CqNuF_YuPfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d211bf3c-1b83-4178-d9c0-e4ec4918345c"
      },
      "source": [
        "show_predictions(\"Will it snow tomorrow in Saclay?\", intent_names, slot_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Intent: GetWeather\n",
            "## Slots:\n",
            "      Will : O\n",
            "        it : O\n",
            "      snow : B-condition_description\n",
            "  tomorrow : B-timeRange\n",
            "        in : O\n",
            "        Sa : B-city\n",
            "       ##c : I-city\n",
            "     ##lay : I-city\n",
            "         ? : O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDijGXG0uQvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "41648799-e982-4a8f-aa78-6f409682f495"
      },
      "source": [
        "show_predictions(\"I would like to listen to Anima by Thom Yorke.\", intent_names, slot_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Intent: PlayMusic\n",
            "## Slots:\n",
            "         I : O\n",
            "     would : O\n",
            "      like : O\n",
            "        to : O\n",
            "    listen : O\n",
            "        to : O\n",
            "        An : B-object_name\n",
            "     ##ima : I-object_name\n",
            "        by : O\n",
            "      Thom : B-artist\n",
            "      York : I-artist\n",
            "       ##e : I-artist\n",
            "         . : O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfwa6MGwuSO8",
        "colab_type": "text"
      },
      "source": [
        "### Turning Predictions into Structured Knowledge\n",
        "\n",
        "A system like Siri shouldn't have to handle any excess information, and ultimately wants to transform a speaker's verbal command into a nice, structured format.\n",
        "\n",
        "<img src=\"https://static1.squarespace.com/static/52656c81e4b06478e0b5ae1e/595416aee3df2810ff2a1d77/5b5c16f9352f53124f46bb33/1569091382090/14064123625_2f8bd0a01b_b.jpg?format=1500w\" width=200>\n",
        "\n",
        "For completeness, the following functions turn the predicted BIO token ids and intent id into a simple structured representation: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udnUVXCvuT4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_predictions(text, intent_names, slot_names,\n",
        "                       intent_id, slot_ids):\n",
        "    info = {\"intent\": intent_names[intent_id]}\n",
        "    collected_slots = {}\n",
        "    active_slot_words = []\n",
        "    active_slot_name = None\n",
        "    for word in text.split():\n",
        "        tokens = tokenizer.tokenize(word)\n",
        "        current_word_slot_ids = slot_ids[:len(tokens)]\n",
        "        slot_ids = slot_ids[len(tokens):]\n",
        "        current_word_slot_name = slot_names[current_word_slot_ids[0]]\n",
        "        if current_word_slot_name == \"O\":\n",
        "            if active_slot_name:\n",
        "                collected_slots[active_slot_name] = \" \".join(active_slot_words)\n",
        "                active_slot_words = []\n",
        "                active_slot_name = None\n",
        "        else:\n",
        "            # Naive BIO: handling: treat B- and I- the same...\n",
        "            new_slot_name = current_word_slot_name[2:]\n",
        "            if active_slot_name is None:\n",
        "                active_slot_words.append(word)\n",
        "                active_slot_name = new_slot_name\n",
        "            elif new_slot_name == active_slot_name:\n",
        "                active_slot_words.append(word)\n",
        "            else:\n",
        "                collected_slots[active_slot_name] = \" \".join(active_slot_words)\n",
        "                active_slot_words = [word]\n",
        "                active_slot_name = new_slot_name\n",
        "    if active_slot_name:\n",
        "        collected_slots[active_slot_name] = \" \".join(active_slot_words)\n",
        "    info[\"slots\"] = collected_slots\n",
        "    return info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5-mstZjuV52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nlu(text, intent_names, slot_names):\n",
        "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n",
        "    outputs = joint_model(inputs)\n",
        "    slot_logits, intent_logits = outputs\n",
        "    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n",
        "    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
        "\n",
        "    return decode_predictions(text, intent_names, slot_names, intent_id, slot_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWKJnB6euX0f",
        "colab_type": "text"
      },
      "source": [
        "Let's test this on the same examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUNcIW8buZmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a07393dd-0f33-4766-ca03-6cb51a2b180d"
      },
      "source": [
        "nlu(\"Book a table for two at Le Ritz for Friday night\", intent_names, slot_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'BookRestaurant',\n",
              " 'slots': {'party_size_number': 'two',\n",
              "  'restaurant_name': 'Le Ritz',\n",
              "  'timeRange': 'Friday'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WruhL1tubsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0c390d70-14b9-48f4-cbb7-931486289ba4"
      },
      "source": [
        "nlu(\"Will it snow tomorrow in Saclay\", intent_names, slot_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'GetWeather',\n",
              " 'slots': {'city': 'Saclay',\n",
              "  'condition_description': 'snow',\n",
              "  'timeRange': 'tomorrow'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiVegtxAudAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec33682e-12a4-46e7-bc4d-71f230a304ee"
      },
      "source": [
        "nlu(\"I would like to listen to Anima by Thom Yorke\", intent_names, slot_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'PlayMusic',\n",
              " 'slots': {'artist': 'Thom Yorke', 'object_name': 'Anima'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM6dR0bl0C7V",
        "colab_type": "text"
      },
      "source": [
        "**Discuss**:\n",
        "\n",
        "We focused on the NLU/NLP aspect of turning a string of words in a verbal command into a simple representation for Siri to utilize.\n",
        "\n",
        "What do you think Siri would actually do next with those structured predictions?\n",
        "\n",
        "[article](https://magoosh.com/data-science/siri-work-science-behind-siri/#:~:text=Technology%20behind%20Siri,into%20its%20corresponding%20textual%20form.&text=This%20way%2C%20Siri%20is%20able%20to%20cater%20to%20various%20accents.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZxnxXzzuedG",
        "colab_type": "text"
      },
      "source": [
        "## Limitations\n",
        "\n",
        "1. **Language**\n",
        "\n",
        "BERT is pretrained primarily on English content. Therefore, it will extract features on English text.\n",
        "\n",
        "Note that there are alternative pretrained models that use a mix of different languages (e.g. [XLM](https://github.com/facebookresearch/XLM/)) and certain models that have been trained on other languages entirely. For instance [CamemBERT](https://camembert-model.fr/) is pretrained on French text. Both kinds of models are available in the transformers package:\n",
        "\n",
        "https://github.com/huggingface/transformers#model-architectures\n",
        "\n",
        "The public SNIPS dataset we used is for fine-tuning in English only. To build a model for another language we would need to collect and annotate a similar corpus (body of text) with diverse, representative samples.\n",
        "\n",
        "\n",
        "2. **Biases in the Pre-Trained Model**\n",
        "\n",
        "The original data used to pre-train BERT was collected from the Internet and contains a multitude of data, including offensive and hateful speech.\n",
        "\n",
        "While using BERT for our voice command understanding system is unlikely to be impacted by those biases, it could be a serious problem for other kinds of applications.\n",
        "\n",
        "It is therefore strongly recommended to spend time auditing any biases that are embedded in pre-trained models before ever actually deploying system that derives from them.\n",
        "\n",
        "3. **Computational Resources**\n",
        "\n",
        "The original BERT model has many parameters which takes up a lot of memory. It is also very computationally intensive and usually requires powerful [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit) or [TPUs](https://en.wikipedia.org/wiki/Tensor_processing_unit) to process data at a *reasonable* speed (both for training and testing).\n",
        "\n",
        "Designing alternative architectures with fewer parameters or more efficient training and prediction methods is still an area of active research.\n",
        "\n",
        "Depending on the problem, simpler architectures based on convolutional neural networks (CNNs) and LSTMs might have a better speed / accuracy trade-off."
      ]
    }
  ]
}